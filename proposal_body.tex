%---------------------------
% section 1
%---------------------------
\section{Topic justification and context}

Throughout the literature, the benefits of effective teaching practices spans from short-term outcomes, like improvements in student achievements \citep{Rockoff_2004, Rivkin_et_al_2005, Duflo_et_al_2009, Hanushek_et_al_2012, Muralidharan_et_al_2013, Chetty_et_al_2014a, Araujo_et_al_2016}; to long-term effects, like the development of executive functions \citep{Araujo_et_al_2016}, increased college attendance, higher salaries, lower possibility of premature parenthood \citep{Chetty_et_al_2014b}, among others. Similarly, the literature has shown most of the negative impacts resulting from the presence of teacher shortages\footnote{\citet{Bertoni_et_al_2020a} defined it as the context in which the teacher's supply, i.e. the number of available teachers in the system, is less than its demand. The authors further elaborate that one of the causes of these shortages is related to the applicants' lower quality or due to their faulty initial training, implying that the shortage can also be conceived as the lack of good quality teachers. In this sense, the evidence of such shortage has been more prevalent, but not decisive, with temporary teachers, as they are usually associated with inferior attributes, compared to their contracted counterparts} or ineffective teaching practices \citep{Duflo_et_al_2009, Hanushek_et_al_2012, Muralidharan_et_al_2013, Duflo_et_al_2015, Ayala_2017, Marotta_2019}.

However, while the evidence have a solid methodological support, some of it have been based on proxy variables that are not consistently related to either teacher effectiveness or quality of instruction \citep{Hanushek_et_al_2006}. Examples of such variables are, out of field teaching\footnote{\citet{Medeiros_et_al_2018} defines it as teachers teaching a subject in which they are not specialized or do not have the appropriate certificate.} \citep{Ingersoll_1998, Dee_et_al_2008, Bertoni_et_al_2020a}; teaching hours \citep{Bruns_et_al_2015}; years of experience or educational degree \citep{Rockoff_2004, Rivkin_et_al_2005, Clotfelter_et_al_2006, Clotfelter_et_al_2007, Hanushek_et_al_2012}; while \citet{Sutcher_et_al_2016} details other proxies used to measure teacher shortage. 

Given the consistency issue of proxy variables, \citet{Hanushek_et_al_2012} pointed out that the analysis of teacher effectiveness has largely turned away from attempts to identify specific characteristics of teachers, and instead has focused its attention to measure the direct relationship between teachers and student outcomes through a value-added analysis\footnote{The method is based on the perspective that a good teacher is one who consistently gets higher achievement from students after other determinants of such are controlled for. For a more detailed explanation of the method refer to \citet{Scherrer_2011}.}. For that reason, considerable uncertainty is still present in the literature, regarding exactly which aspects of teachers are key for the student's learning and whether those qualities can be measured \citep{Rockoff_2004, Clotfelter_et_al_2006}.

Because the evidence significantly support the perception that teachers are the main driver behind the student's learning processes and outcomes, the main agenda of any educational authority should be the design of an assessment system that can attract, select, develop, and retain the most effective teachers \citep{Elacqua_et_al_2018}. But first, it would be necessary to define the Educational Performance Standards (EPS) that best agrees with the country's context. With the EPS establishment, the educational authorities can set clear expectations about what a "good" teacher should know and know to do \citep{Hincapie_et_al_2020}, and eventually, assess the teacher shortage.

While the specific requirements for a "good "teacher are not as easy to define, \citet{Hincapie_et_al_2020} has hinted that most of them can be largely grouped into two: (i) to have the disciplinary knowledge and pedagogical practices adequate to the classroom characteristics, context and teaching level, and (ii) to display such knowledge and practices in the classroom, using the appropriate material and technological resources available. 

As one can infer, from the previous general conditions and the slew evidence, knowledge is a relevant observable factor that it is consistently associated with teacher effectiveness and growth in student's achievement \citep{Santibanez_2006, Clotfelter_et_al_2006, Clotfelter_et_al_2007, Hanushek_et_al_2006, Marshall_2009, Rockoff_et_al_2011, Kane_et_al_2011, Kane_et_al_2012, Ome_2012, Metzler_et_al_2012, Kane_et_al_2013, Araujo_et_al_2016, Bietenbeck_et_al_2018, Estrada_2019}; in that sense, its measurement should of interest for any educational authority.

While \citet{Bertoni_et_al_2020b} had advocated for use of multiple instruments, and in fact, the measurement of knowledge has a myriad of available tools, we have to keep in mind that the educational authorities are bound by budgetary constraints. Is in this setting that, compared to other instruments, valid\footnote{the extend to which a measurement tool is well-founded and accurately corresponds to the real measure \citep{Kelley_1927}} and reliable\footnote{the overall consistency of a measure under consistent conditions.} standardized tests\footnote{Assessment instrument in which the implementation, questions, scoring processes, and interpretations are consistent with a predetermined or typified way. The instrument is usually composed of questions or items that fulfill three conditions: (i) they are polytomous, i.e. they have multiple choices, (ii) the choice categories are nominal, i.e. do not present any specific order, and (iii) there is only one "correct" category or answer \citep{Rivera_2019}} shines because not only are cost-effective and much simpler to implement \citep{Hincapie_et_al_2020}, but they are among the most subjective-free tools available.

However, as no instrument is perfect, the teacher's subject knowledge scores likely reflect considerable noise or measurement error \citep{Metzler_et_al_2012}. As established by \citet{Angrist_et_al_1999}, measurement error in the explanatory variable may lead to a downward bias in the estimated coefficient, meaning that, the previous evidence on teacher's knowledge could be an attenuated reflection of the true effect. On the other hand, the use of one composite value, i.e. the score, does not allow to test which specific factors (if any) leads to better or worse teacher's performance, making also difficult to know which teacher should be hired or what should be done to train them \citep{Hanushek_et_al_2012}.

But beyond the use of test results as explanatory variables in modeling processes, there is one more pressing argument on why the measurement error issue should be addressed: approximately 60\% of the Caribbean and Latin American countries use standardized test scores as part or as a main teacher's selection tool \citep{Hincapie_et_al_2020}. For this reason, the educational authorities could benefit from testing if the scores thresholds used for the selection are appropriately set, and what kind of teacher are they letting in to the system, as a result.


In summary, 

- Paragraph's conclusion: 


Second, it would be valuable to develop richer measures of teacher quality which go beyond the mean test score impacts that we analyzed here. \citep{Chetty_et_al_2014a}

\citep{Hincapie_et_al_2020}
Las falencias en la calidad de la formación inicial y las características de los interesados en ingresar a la profesión docente en la región (reseñadas por \citep{Elacqua_et_al_2018}), sumadas a la dificultad que tienen los ministerios de educación para remover del cargo a docentes con bajos niveles de desempeño, convierten a las evaluaciones de ingreso a la carrera en un elemento esencial para identificar mejor las características y capacidades de los futuros docentes. En ese sentido, continuar con los procesos de mejora y de implementación adecuada de esta evaluación podría traer beneficios en la calidad de la fuerza docente en la región. Aunque la evidencia aún es escasa, estudios para Colombia (Ome, 2012; Brutti y Sánchez, 2017) y México (Estrada, 2019) sugieren que estos sistemas de selección (con evaluaciones para ingresar a la carrera) están teniendo algunos impactos positivos en la calidad educativa de los países que los implementan.

De manera similar, en lo que respecta a los temas disciplinares, pruebas en Perú, Chile y México y estudios internacionales aplicados a los propios docentes indican que sus conocimientos de matemáticas son insatisfactorios \citep{Elacqua_et_al_2018}.


- Paragraph's main point: How the results are used


Todas estas políticas deben tener como objetivo desarrollar y potenciar los conocimientos disciplinares y las habilidades pedagógicas de los docentes. Las evaluaciones docentes pueden ayudar a identificar las diferencias de desempeño entre los profesores. Además, el uso adecuado de sus resultados puede otorgar la información necesaria para aprovechar al máximo sus fortalezas, buscar superar las falencias, y potenciar la excelencia en la profesión. \citep{Hincapie_et_al_2020}


La segunda característica necesaria dentro de la teoría de cambio (reflejada en el segundo punto del primer círculo de la cadena) es el uso que se les da a los resultados de la evaluación. \citep{Hincapie_et_al_2020}


- Paragraph's idea 1: how they are used

la Organización para la Cooperación y el Desarrollo Económicos (OCDE) este uso puede tener dos objetivos: i) mejorar las prácticas y las habilidades pedagógicas y/o disciplinares a partir del diagnóstico y la vinculación a programas de desarrollo profesional diseñados para superar los resultados; ii) mejorar la composición y la motivación de la fuerza docente por medio del otorgamiento de bonificaciones, reconocimientos especiales o ascensos para aquellos docentes con resultados excelentes o excluir al docente del sistema —o al menos retirarlo de las aulas— en los casos en que muestre de manera consistente que no cumple con las condiciones requeridas por la profesión (OCDE, 2009 y 2013).
El problema que surge en relación con estos dos objetivos (plasmados en el segundo eslabón del gráfico 2.1) es que son difíciles de lograr con una única herramienta de evaluación.
Para poder detectar los aspectos por mejorar de las prácticas y el conocimiento pedagógico y disciplinar, y reconocer la excelencia docente, es necesario que los docentes estén completamente abiertos a revelar sus prácticas y logros y dispuestos a compartirlos con las autoridades \citep{Hincapie_et_al_2020}

Igualmente, una vez que los procesos finalizan, debe decidirse cómo entregar la información recolectada a los docentes y, lo que es más importante aún, cómo utilizarla para asegurar la mejora de la labor pedagógica. \citep{Hincapie_et_al_2020}



- Paragraph's idea 2: evidence about impacts on the use of the results


- Paragraph's conclusion: results can have serious impacts into multiple facets




- Closing thoughts

en este documento tratamos de responder a dos preguntas fundamentales: ¿cómo identificamos y seleccionamos a los mejores docentes? y ¿cómo los asignamos a las escuelas de una manera eficiente y equitativa? \citep{Bertoni_et_al_2020b}



%---------------------------
% section 2
%---------------------------
\section{Methods}

Four measurements issues receive considerable attention in the research literature: (a) random measurement error, (b) the focus of test on particular portions of the achievement distribution, (c) cardinal versus ordinal comparisons of test scores, and (d) the multidimensionaly of educational outcomes. Not only do the test measurements issues introduce noise into the estimates of the teacher effectiveness, but they also bias upwards estimates of the variance in teacher quality \citep{Hanushek_et_al_2012}. While this was mentioned for the value-added measures it is equally valid for the standardized evaluation of teachers.


We address measurement error by correcting the estimated coefficients using a reliability ratio estimated on the basis of answers to all items on the teacher tests (see Section 5.3).


- Paragraph's main point: what method are you using?

one can improve the value-added measures if we incorporate other measures of teacher quality, such as teacher characteristics \citep{Chetty_et_al_2014a}

- Paragraph's idea 1: IRT and the focus on items

De esta forma, mientras que los modelos para respuestas dicot?micas, tales como Rasch (\citealp{Rasch1980}), de uno, dos, tres par?metros (\citealp{Lord_Nov2008}) y cuatro par?metros (\citealp{McDonald1967}), expresan la probabilidad de elegir la alternativa correcta en funci?n de la ``habilidad'' del individuo; el \textbf{Modelo de Respuesta Nominal (NRM)} y todas sus extensiones (\citealt{Bock1972}  y \citealt[cap?tulo 2]{Linden1997}), expresa la probabilidad de elegir cada alternativa de la pregunta en funci?n de la misma ``habilidad''.

A diferencia de los modelos de respuesta graduada (\citealt{Samejima1969, Samejima1972} y \citealt[cap?tulo 5]{Ham_Swam1991}), el NRM no se sustenta sobre el concepto de la dicotomizaci?n de las alternativas, que derivan en los umbrales por categor?as caracteristicos de los modelos mencionados; por el contrario, la probabilidad correspondiente a cada alternativa es modelada directamente, implementando una generalizaci?n multivariada del modelo de rasgos latentes log?stico (\citealt{Bock1972}, \citealt{Ostini2006}).



- Paragraph's idea 2: SEM and the focus on abilities




- Paragraph's idea 3: IRT and SEM equivalence (evidence)

\citep{Brown_2015}
The potential consequences of treating categorical variables as continuous variables in CFA are manifold: (1) They produce attenuated estimates of the relationships (correlations) among indicators, especially when there are floor or ceiling effects; (2) they lead to “pseudofactors” that are artifacts of item difficulty or extremeness; and (3) they produce incorrect test statistics and standard errors. ML can also produce  incorrect parameter estimates, such as in cases where marked floor or ceiling effects exist in purportedly interval-level measurement scales (i.e., because the assumption of linear relationships does not hold).


Rasch Model with SEM

1. Requires to set the loadings = 1 in all items 
(there are no evidence that different items should load differently in all sub-factors, if that happen then we can say that an item does not behave good)

2. Thresholds can be transformed into difficulty parameters. They will be from the normal ogive model.


Evidence:
It is well known that factor analysis with binary outcomes is equivalent to a two-parameter normal ogive IRT model (e.g., Ferrando & Lorenza-Sevo, 2005; Glöckner-Rist & Hoijtink, 2003; \citep{Kamata_et_al_2008, Takane_et_al_1987}.

Item difficulties have been alternatively referred to in the IRT literature as item threshold or item location parameters. In fact, item difficulty parameters are analogous to item thresholds (t) in CFA with categorical outcomes \citep{Muthen_et_al_1991}.

Item discrimination parameters are analogous to factor loadings in CFA and EFA because they represent the relationship between the latent trait and the item  responses.

Muthén (1988; Muthén et al., 1991) has shown that MIMIC models (see Chapter 7) with categorical indicators are equivalent to DIF analysis in the IRT framework (see also Meade & Lautenschlager, 2004).

Muthén (1988; Muthén et al., 1991) notes that the MIMIC framework offers several potential advantages over IRT. These include the ability to (1) use either continuous covariates (e.g., age) or categorical background  variables (e.g., gender); (2) model a direct effect of the covariate on the latent variable (in addition to direct effects of the covariate on test items); (3) readily  evaluate multidimensional models (i.e., measurement models with more than one factor); and (4) incorporate an error theory (e.g., measurement error covariances). Indeed, a general advantage of the covariance structure analysis approach is that the IRT model can be  embedded in a larger structural equation model (e.g., Lu, Thomas, & Zumbo, 2005).


De esta forma, en el contexto de una evaluaci?n estandarizada, suponemos que $n$ sujetos responden $p$ ?tems de opci?n m?ltiple eligiendo \textbf{una sola} alternativa de $m_j$ disponibles, las mismas que pueden variar de ?tem a ?tem y poseen un orden arbitrario. Entonces, el NRM define \textbf{\textit{Funciones de Respuestas de las Categor?as del ?tem}} (ICRF, acorde con \citealp{Ostini2006}) o Curvas Caracter?sticas de la Alternativas del ?tem (IOCC, acorde con \citealp{Ham_Swam1991}) de la siguiente manera:
\begin{equation}
	P_{jk}(\theta_i) = \dfrac{e^{z_{jk}(\theta_i)}}{\sum_{h=1}^{m}e^{z_{jh}(\theta_i)}} 
\end{equation}

Donde:
\begin{equation*}
z_{jk} = a_{jk}\theta_i + c_{jk} \quad \forall \quad i = 1, \dots, n; \quad j = 1, \dots, p \text{;} \quad k = 1, \dots, m_j
\end{equation*}

El par?metro $\theta_i$ representa la ``habilidad'' del individuo $i$, $a_{jk}$ corresponde al par?metro de discriminaci?n de la alternativa $k$ del ?tem $j$ y $c_{jk}$ es proporcional a la ``popularidad'' de la alternativa $k$ del ?tem $j$. El vector compuesto por los vectores $z_{j1}, z_{j2}, \dots z_{j m_j}$ es usualmente definido como el vector \textit{logit multinomial}. La presente parametrizaci?n del modelo es expresada en t?rminos del intercepto y la pendiente de las ICRFs; sin embargo, la literatura utiliza una parametrizaci?n que hace la estimaci?n computacionalmente m?s eficiente.



- Paragraph's idea 4: what can be gain from this merge

De la parametrizaci?n anterior se espera que, al igual que los modelos para respuestas dicot?micas, la ICRF de la alternativa ``correcta'' sea monot?nicamente creciente respecto a la ``habilidad'', mientras que la forma de las ICRFs de los distractores depender? de como la alternativa sea percibida por el evaluado (\citealp{Ham_Swam1991}). De este modo, se plantea estudiar la formulaci?n, supuestos, caracter?sticas y propiedades del NRM.

De manera complementaria al estudio del modelo, el presente proyecto plantea la estimaci?n de los par?metros de inter?s a trav?s de simulaciones de \textbf{Cadenas de Markov de Montecarlo (MCMC)}, perteneciente a los m?todos de inferencia bayesiana. Se elige los m?todos bayesianos debido a que: (i) elimina los problemas de no convergencia y estimaci?n impropia de los par?metros encontrados en los procedimientos de m?xima verosimilitud conjunta y/o marginal \citep{Ham_Swam_Rog1991}, (ii) bajo escenarios en los que la complejidad del modelo incrementa, el m?todo se vuelve m?s atractivo, pues usa simulaciones en vez de m?todos num?ricos; (iii) los modelos MCMC se vuelven particularmente ?tiles cuando los datos son dispersos o cuando es poco probable que la teor?a asint?tica se mantenga \citep{Fox2010}; (iv) la flexibilidad y escalabilidad de las soluciones implementadas y (v) una mayor capacidad de recuperaci?n de par?metros de inter?s, de los cuales existen muchos ejemplos (\citealp{Hsi_Proc_Hou_Teo2010}, \citealp{Tarazona2013}, entre otros).


- Paragraph's idea 5: What are the difficulties


- Paragraph's conclusion: SEM/IRT merge provides multiple benefits




%---------------------------
% section 3
%---------------------------
\section{Data}

Con respecto a los requisitos generales, para ser docente en Perú es necesario poseer el título de profesor o licenciado en educación, otorgado por una institución de formación docente acreditada en el país o en el exterior (en este último caso, el título debe ser revalidado en el Perú) 16 Además de los requisitos generales también se deben cumplir requisitos específicos, por ejemplo: a) manejar fluidamente la lengua materna de los estudiantes y conocer la cultura local para postular a vacantes de instituciones educativas pertenecientes a educación intercultural bilingüe (EIB); b) acreditar la especialización en la modalidad para postular a vacantes de instituciones educativas pertenecientes a educación básica especial (EBE); y c) se permite enseñar en inicial a los docentes con título de profesor o de licenciado en educación en la modalidad de educación básica regular (EBR) en el nivel primaria, con estudios concluidos de segunda especialidad en educación inicial y con experiencia mínima de dos (02) años lectivos en el nivel inicial.


- Paragraph's main point: What data do we have?

Finalmente, el modelo investigado ser? aplicado a un conjunto de datos reales pertenecientes al sector educativo. 


- Paragraph's idea 1: Standardized MCQ in Peru for multiple purposes

En el actual escenario de la revalorizaci?n de la carrera magisterial\footnote{Ley N? 28044, Ley General de Educaci?n}\footnote{Ley N? 29944, Ley de Reforma Magisterial}\footnote{Decreto Supremo N? 011-2012-ED, que aprueba el Reglamento de La Ley de Educaci?n}\footnote{Decreto Supremo N? 004-2013-ED, que aprueba el Reglamento de la Ley de Reforma Magisterial, y sus modificaciones}, el Ministerio de Educaci?n del Per? (MINEDU) aprob? en el a?o $2012$ e inici? la implementaci?n en el a?o $2014$ las evaluaciones a docentes con el prop?sito de: (i) evaluar las capacidades y/o competencias de los docentes nombrados en las especialidades que corresponden a su ense?anza y (ii) revalorizar las escalas salariales de los docentes nombrados. En este contexto, en el a?o $2015$, el ministerio aplic? la evaluaci?n de ``Ingreso a la Carrera Publica Magisterial y Contratacion Docente'' (en adelante \textbf{Nombramiento 2015}), la cual permiti? el ingreso de nuevos docentes a la primera de las siete escalas de la carrera magisterial.


- Paragraph's idea 2: Definition of the sample and variables

El presente proyecto opt? por implementar el modelo investigado en $40$ de los $90$ ?tems disponibles de Nombramiento $2015$, aplicados a $11826$ docentes de la especialidad de Matem?tica de la Modalidad de Educaci?n B?sica Regular Nivel Secundaria. El instrumento se encuentra dise?ado para medir un \textbf{\textit{trazo latente unidimensional}} que corresponde a las \textbf{\textit{competencias pedag?gicas y de especialidad}} que los docentes poseen. La elecci?n del modelo se sustent? en que este no solo provee informaci?n acerca de la alternativa elegida (presuntamente ``correcta''), sino tambien, permite conocer la ``popularidad'' con la que el individuo percibe el resto de categor?as disponibles, informaci?n especialmente valiosa para el an?lisis de distractores y validez te?rica de constructo de los ?tems utilizados en el instrumentos de evaluaci?n.

- Paragraph's idea 3: Composition of the exam
- Paragraph's idea 4: Selection of factors and why
- Paragraph's conclusion: The process can be performed in this data

En conclusi?n, el presente proyecto de tesis estudiar? los supuestos, propiedades y caracter?sticas del Modelo de Respuesta Nominal (NRM) e implementar? la estimaci?n de sus par?metros desde el enfoque de la  inferencia bayesiana. Entre los t?picos que adicionalmente ser?n presentados se encuentran: (i) estudios de simulaci?n que comparan la recuperaci?n de par?metros de inter?s entre el m?todo cl?sico de estimaci?n y el bayesiano y (ii) la aplicaci?n a un conjuntos de datos reales del sector educativo, acorde con lo detallado en parrafos previos.



%---------------------------
% section 3
%---------------------------
\section{Thesis objectives}

El objetivo general de la tesis consiste en estudiar la formulaci?n, supuestos, caracter?sticas y propiedades del \textbf{Modelo de Respuesta Nominal (NRM)}   en el contexto de la Teor?a de Respuesta al ?tem (IRT). Del mismo modo, se pretende realizar un estudio de simulaci?n que compare el m?todo cl?sico de estimaci?n del NRM frente a los m?todos bayesianos. Finalmente, se aplicar? el modelo descrito a un conjuntos de datos reales del sector educativo, desde el enfoque de la inferencia bayesiana. De manera espec?fica:

\begin{itemize}
\item Se realizar? una extensiva revisi?n de la literatura acerca del modelo de inter?s.
\item Se estudiar?n los supuestos, caracter?sticas y propiedades del modelo, desde la perspectiva cl?sica y bayesiana.
\item Se implementar?n m?todos de inferencia bayesiana para la estimaci?n de los par?metros de inter?s.
\item Se realizar?n estudios de simulaci?n para comprobar la capacidad de recuperaci?n de los par?metros de inter?s por parte del m?todo cl?sico y bayesiano.
\item Se aplicar? el modelo de inter?s a un conjunto de datos reales pertenecientes al sector educativo.
\end{itemize}